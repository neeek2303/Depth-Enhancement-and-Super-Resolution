{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from numpy.lib.stride_tricks import as_strided as ast\n",
    "import tqdm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fspecial_gauss(size, sigma):\n",
    "    \"\"\"\n",
    "        Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g/g.sum()\n",
    "\n",
    "def ssim(img1, img2, max_value, L, cs_map=False):\n",
    "    \"\"\"Return the Structural Similarity Map corresponding to input images img1 \n",
    "    and img2 (images are assumed to be uint8)\n",
    "    \n",
    "    This function attempts to mimic precisely the functionality of ssim.m a \n",
    "    MATLAB provided by the author's of SSIM\n",
    "    https://ece.uwaterloo.ca/~z70wang/research/ssim/ssim_index.m\n",
    "    \"\"\"\n",
    "    #range [0,1]\n",
    "    img1 = img1.astype(np.float64) / max_value\n",
    "    img2 = img2.astype(np.float64) / max_value\n",
    "    size = 11\n",
    "    sigma = 1.5\n",
    "    window = fspecial_gauss(size, sigma)\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "    mu1 = signal.fftconvolve(window, img1, mode='valid')\n",
    "    mu2 = signal.fftconvolve(window, img2, mode='valid')\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    sigma1_sq = signal.fftconvolve(window, img1*img1, mode='valid') - mu1_sq\n",
    "    sigma2_sq = signal.fftconvolve(window, img2*img2, mode='valid') - mu2_sq\n",
    "    sigma12 = signal.fftconvolve(window, img1*img2, mode='valid') - mu1_mu2\n",
    "    if cs_map:\n",
    "        return (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2)), \n",
    "                (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
    "    else:\n",
    "        return ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_shape(shape):\n",
    "    '''\n",
    "    Normalize numpy array shapes so they're always expressed as a tuple, \n",
    "    even for one-dimensional shapes.\n",
    "\n",
    "    Parameters\n",
    "        shape - an int, or a tuple of ints\n",
    "\n",
    "    Returns\n",
    "        a shape tuple\n",
    "    '''\n",
    "    try:\n",
    "        i = int(shape)\n",
    "        return (i,)\n",
    "    except TypeError:\n",
    "        # shape was not a number\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        t = tuple(shape)\n",
    "        return t\n",
    "    except TypeError:\n",
    "        # shape was not iterable\n",
    "        pass\n",
    "\n",
    "    raise TypeError('shape must be an int, or a tuple of ints')\n",
    "\n",
    "\n",
    "def sliding_window(a,ws,ss = None,flatten = False):\n",
    "    '''\n",
    "    Return a sliding window over a in any number of dimensions\n",
    "\n",
    "    Parameters:\n",
    "        a  - an n-dimensional numpy array\n",
    "        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size \n",
    "             of each dimension of the window\n",
    "        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the \n",
    "             amount to slide the window in each dimension. If not specified, it\n",
    "             defaults to ws.\n",
    "        flatten - if True, all slices are flattened, otherwise, there is an \n",
    "                  extra dimension for each dimension of the input.\n",
    "\n",
    "    Returns\n",
    "        an array containing each n-dimensional window from a\n",
    "\n",
    "    from http://www.johnvinyard.com/blog/?p=268\n",
    "    '''\n",
    "\n",
    "    if None is ss:\n",
    "        # ss was not provided. the windows will not overlap in any direction.\n",
    "        ss = ws\n",
    "    ws = norm_shape(ws)\n",
    "    ss = norm_shape(ss)\n",
    "\n",
    "    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every \n",
    "    # dimension at once.\n",
    "    ws = np.array(ws)\n",
    "    ss = np.array(ss)\n",
    "    shape = np.array(a.shape)\n",
    "\n",
    "\n",
    "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
    "    ls = [len(shape),len(ws),len(ss)]\n",
    "    if 1 != len(set(ls)):\n",
    "        raise ValueError(\\\n",
    "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
    "\n",
    "    # ensure that ws is smaller than a in every dimension\n",
    "    if np.any(ws > shape):\n",
    "        raise ValueError('ws cannot be larger than a in any dimension. a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
    "\n",
    "    # how many slices will there be in each dimension?\n",
    "    newshape = norm_shape(((shape - ws) // ss) + 1)\n",
    "    # the shape of the strided array will be the number of slices in each dimension\n",
    "    # plus the shape of the window (tuple addition)\n",
    "    newshape += norm_shape(ws)\n",
    "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
    "    # the array's strides (tuple addition)\n",
    "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
    "    strided = ast(a,shape = newshape,strides = newstrides)\n",
    "    if not flatten:\n",
    "        return strided\n",
    "\n",
    "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
    "    # the new array is a flat list of slices.\n",
    "    meat = len(ws) if ws.shape else 0\n",
    "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
    "    dim = firstdim + (newshape[-meat:])\n",
    "    # remove any dimensions with size 1\n",
    "    dim = filter(lambda i : i != 1,dim)\n",
    "    return strided.reshape(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_val_ssim_filter(fname, max_value=5100., L=1., h_val=10, sourse_path='/all_data/hdd/un_depth/Scannet_all_data/', save_path='/all_data/hdd/un_depth/Scannet_ssim/'):\n",
    "    \n",
    "    depth_lq = imageio.imread(os.path.join(sourse_path, 'raw', fname))\n",
    "    depth_sr = imageio.imread(os.path.join(sourse_path, 'render', fname))\n",
    "    H, W = depth_lq.shape\n",
    "    H_sr, W_sr = depth_sr.shape\n",
    "    \n",
    "    fname_base, ext = os.path.splitext(fname)\n",
    "    resize = A.Resize(height=H_sr, width=W_sr, p=1)\n",
    "    img = imageio.imread(os.path.join(sourse_path, 'img', fname_base + '.jpg'))\n",
    "    img = resize(image=img)['image']\n",
    "    \n",
    "    if (np.max(depth_lq) <= max_value) and (np.max(depth_sr) <= max_value):\n",
    "        \n",
    "        ssim_mtrx = ssim(depth_lq, depth_sr[0::2, 0::2], max_value, L)\n",
    "        \n",
    "        H_p, W_p = ssim_mtrx.shape\n",
    "        assert ((H - H_p) % 2 == 0) and ((W - W_p) % 2 == 0) and ((H - H_p) // 2 == (W - W_p) // 2 ), 'check how fftconvolve produce valid mode'\n",
    "        pad = (H - H_p) // 2        #valid mode don't return values influenced by zero-padding\n",
    "        depth_sr = depth_sr[2*pad:-2*pad, 2*pad:-2*pad]\n",
    "        img = img[2*pad:-2*pad, 2*pad:-2*pad, :]\n",
    "        depth_lq = depth_lq[pad:-pad, pad:-pad]\n",
    "    \n",
    "        ssim_patch = sliding_window(ssim_mtrx, (320, 320), (64, 64))\n",
    "        ssim_idx = ssim_patch.mean(axis=(2,3)) > 0.8\n",
    "        n_ssim = ssim_idx.sum()\n",
    "\n",
    "        if n_ssim > 0:\n",
    "            \n",
    "            depth_sr_patch = sliding_window(depth_sr, (640,640), (128,128))\n",
    "            hole_idx = (depth_sr_patch <= h_val).sum(axis=(2,3)) == 0\n",
    "            \n",
    "            final_idx = hole_idx * ssim_idx\n",
    "            n_good = final_idx.sum()\n",
    "            if n_good > 0:\n",
    "                patch_idx = np.argwhere(final_idx)\n",
    "        \n",
    "                depth_lq_patch = sliding_window(depth_lq, (320, 320), (64, 64))\n",
    "                img_patch = sliding_window(img, (640,640,3), (128, 128, 1))\n",
    "                \n",
    "                depth_gt_good = depth_sr_patch[final_idx][:, 0::2, 0::2]\n",
    "                depth_lq_good = depth_lq_patch[final_idx]\n",
    "                img_good = img_patch[final_idx]\n",
    "                depth_sr_good = depth_sr_patch[final_idx]\n",
    "                for i in range(n_good):\n",
    "                    imageio.imsave(os.path.join(save_path, 'img', '{}_{}_{}{}'.format(fname_base, patch_idx[i,0], patch_idx[i,1], \".jpg\")), img_good[i,0])\n",
    "                    imageio.imsave(os.path.join(save_path, 'raw', '{}_{}_{}{}'.format(fname_base, patch_idx[i,0], patch_idx[i,1], ext)), depth_lq_good[i])\n",
    "                    imageio.imsave(os.path.join(save_path, 'render', '{}_{}_{}{}'.format(fname_base, patch_idx[i,0], patch_idx[i,1], ext)), depth_gt_good[i])\n",
    "                    imageio.imsave(os.path.join(save_path, 'hr','{}_{}_{}{}'.format(fname_base, patch_idx[i,0], patch_idx[i,1], ext)), depth_sr_good[i])\n",
    "            else:\n",
    "                return\n",
    "        else:\n",
    "            return\n",
    "    else:\n",
    "         return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48556/48556 [1:14:10<00:00, 10.91it/s]  \n"
     ]
    }
   ],
   "source": [
    "# sourse_path = '/all_data/hdd/un_depth/Scannet_all_data/' \n",
    "# fnames = sorted(os.listdir(os.path.join(sourse_path, 'raw')))\n",
    "# n_processes = 30\n",
    "# with Pool(n_processes) as p:   \n",
    "#     res = list(tqdm.tqdm(p.imap(func=max_val_ssim_filter, iterable=fnames), total=len(fnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_ssim/'\n",
    "img = sorted(os.listdir(os.path.join(path,'img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_env(files):\n",
    "    count = {}\n",
    "    for f in tqdm.tqdm(files):\n",
    "        count[f.split(\"_\")[0]] = count.get(f.split(\"_\")[0], 0) + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96744/96744 [00:00<00:00, 753078.48it/s]\n"
     ]
    }
   ],
   "source": [
    "count = count_env(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene(count, n_get):\n",
    "    n_test = 0\n",
    "    scenes = []\n",
    "    while n_test < n_get:\n",
    "        scene, n = random.choice(list(count.items()))\n",
    "        n_test += n\n",
    "        scenes.append(scene)\n",
    "        del count[scene]\n",
    "    return scenes, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene, count = get_scene(count, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_scene(fnames, scene, path, save_path):\n",
    "    for f in tqdm.tqdm(fnames):\n",
    "        if f.split(\"_\")[0] in scene:\n",
    "            name = f.split('.')[0]\n",
    "            os.rename(os.path.join(path, 'img', name+'.jpg'), os.path.join(save_path, 'img', name+'.jpg'))\n",
    "            os.rename(os.path.join(path, 'raw', name+'.png'), os.path.join(save_path, 'raw', name+'.png'))\n",
    "            os.rename(os.path.join(path, 'render', name+'.png'), os.path.join(save_path, 'render', name+'.png'))\n",
    "            os.rename(os.path.join(path, 'hr', name+'.png'), os.path.join(save_path, 'hr', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96744/96744 [00:01<00:00, 60904.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# mv_scene(img, test_scene, path, '/all_data/hdd/un_depth/Scannet_ssim/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scene, count = get_scene(count, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96744/96744 [00:00<00:00, 166317.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# mv_scene(img, val_scene, path, '/all_data/hdd/un_depth/Scannet_ssim/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./test_scene', np.array(test_scene))\n",
    "np.save('./val_scene', np.array(val_scene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sorted(os.listdir(os.path.join(path,'img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76563/76563 [00:00<00:00, 683505.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = count_env(img)\n",
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA_scene, count = get_scene(count, len(img)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainA_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76563/76563 [00:03<00:00, 20364.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# mv_scene(img, trainA_scene, path, '/all_data/hdd/un_depth/Scannet_ssim/trainA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_all_data/'\n",
    "img = sorted(os.listdir(os.path.join(path,'img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(fname, sourse_path='/all_data/hdd/un_depth/Scannet_all_data/'):\n",
    "    resize = A.Resize(height=960, width=1280, p=1)\n",
    "    img = imageio.imread(os.path.join(sourse_path, 'img', fname))\n",
    "    img = resize(image=img)['image']\n",
    "    imageio.imsave(os.path.join(sourse_path, 'resize_img', fname), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48556/48556 [02:45<00:00, 293.47it/s]\n"
     ]
    }
   ],
   "source": [
    "n_processes = 30\n",
    "with Pool(n_processes) as p:   \n",
    "    res = list(tqdm.tqdm(p.imap(func=resize_img, iterable=img), total=len(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy full size for trainA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_scene(fnames, scene, path, save_path):\n",
    "    for f in tqdm.tqdm(fnames):\n",
    "        name = f.split('.')[0]\n",
    "        if name in scene:\n",
    "            copyfile(os.path.join(path, 'resize_img', name+'.jpg'), os.path.join(save_path, 'img', name+'.jpg'))\n",
    "            copyfile(os.path.join(path, 'raw', name+'.png'), os.path.join(save_path, 'raw', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_all_data/'\n",
    "img = sorted(os.listdir(os.path.join(path,'resize_img')))\n",
    "img_crop = sorted(os.listdir('/all_data/hdd/un_depth/Scannet_ssim/trainA/img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA_names = set()\n",
    "for f in img_crop:\n",
    "    trainA_names.add(f.split('.')[0][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6221"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainA_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48556/48556 [00:02<00:00, 21441.99it/s]\n"
     ]
    }
   ],
   "source": [
    "cp_scene(img, trainA_names, path, '/all_data/hdd/un_depth/Scannet_ssim/trainA/full_size/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy full size for valA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop = sorted(os.listdir('/all_data/hdd/un_depth/Scannet_ssim/valA/img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valA_names = set()\n",
    "for f in img_crop:\n",
    "    valA_names.add(f.split('.')[0][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valA_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48556/48556 [00:00<00:00, 133714.90it/s]\n"
     ]
    }
   ],
   "source": [
    "cp_scene(img, valA_names, path, '/all_data/hdd/un_depth/Scannet_ssim/valA/full_size/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy full size for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_ssim/test'\n",
    "img = sorted(os.listdir(os.path.join(path,'img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frame(files):\n",
    "    count = {}\n",
    "    for f in tqdm.tqdm(files):\n",
    "        count[f.split('.')[0][:-4]] = count.get(f.split('.')[0][:-4], 0) + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15123/15123 [00:00<00:00, 550855.49it/s]\n"
     ]
    }
   ],
   "source": [
    "count = count_frame(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_npatch(count, n_patch):\n",
    "    scene = []\n",
    "    for k,v in count.items():\n",
    "        if v >= n_patch:\n",
    "            scene.append(k)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_full_test = get_frame_npatch(count, 11)\n",
    "len(scene_full_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_frame(fnames, scene, path, save_path):\n",
    "    for f in tqdm.tqdm(fnames):\n",
    "        name = f.split('.')[0]\n",
    "        if name in scene:\n",
    "            copyfile(os.path.join(path, 'resize_img', name+'.jpg'), os.path.join(save_path, 'img', name+'.jpg'))\n",
    "            copyfile(os.path.join(path, 'raw', name+'.png'), os.path.join(save_path, 'raw', name+'.png'))\n",
    "            copyfile(os.path.join(path, 'render', name+'.png'), os.path.join(save_path, 'render', name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/all_data/hdd/un_depth/Scannet_all_data/'\n",
    "img = sorted(os.listdir(os.path.join(path,'resize_img')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48556/48556 [00:00<00:00, 65979.21it/s]\n"
     ]
    }
   ],
   "source": [
    "cp_frame(img, scene_full_test, path,'/all_data/hdd/un_depth/Scannet_ssim/test/full_size/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
